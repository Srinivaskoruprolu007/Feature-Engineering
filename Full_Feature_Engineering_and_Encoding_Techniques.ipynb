{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "cell_execution_strategy": "setup"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eQy_rlu_PQA8"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# let's load the mercedes benz data for demonistartion,  only the categorical variables\n",
        "data = pd.read_csv('/content/mercedesbenz.csv', usecols=['X1', 'X2', 'X3', 'X4', 'X5', 'X6'])\n",
        "data.head()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# let's have a look at how many labels each variable has\n",
        "for col in data.columns:\n",
        "    print(col, ': ', len(data[col].unique()), ' labels')"
      ],
      "metadata": {
        "id": "8ZISt-1RQwpH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# let's examine how many columns we will obtain after one hot encoding these variables\n",
        "pd.get_dummies(data, drop_first=True).shape"
      ],
      "metadata": {
        "id": "FWW5LgqIRdYk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can see that from just 6 intial categories, but we ended up with 117 columns.\n",
        "what can we do instead ?\n"
      ],
      "metadata": {
        "id": "WYflaU2qTJuV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Let's find the 10 most frequent catergories for the variables X2\n",
        "data.X2.value_counts().sort_values(ascending=False).head(20)"
      ],
      "metadata": {
        "id": "l2jMAFSJR6yr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# let's make a list of most frequent categories of the variable X2\n",
        "top_10 = [x for x in data.X2.value_counts().sort_values(ascending=False).head(10).index]\n",
        "top_10"
      ],
      "metadata": {
        "id": "b3Nng-trdHeb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# and now we make the 10 binary variables\n",
        "for label in top_10:\n",
        "    data[label] = np.where(data['X2']==label, 1, 0)\n",
        "data[['X2']+top_10].head(40)"
      ],
      "metadata": {
        "id": "UR8DZOyXeRTF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# get whole set of dummy variables, for all categorical variables\n",
        "def one_hot_encoding(df, variable, top_x_labels):\n",
        "  # function to create the dummy variables for the most frequent labels\n",
        "  # we can vary the number of most frequent labels that we encode\n",
        "  for label in top_x_labels:\n",
        "    df[variable+'_'+label] = np.where(data[variable]==label, 1, 0)\n",
        "\n",
        "# read the data\n",
        "data = pd.read_csv('/content/mercedesbenz.csv', usecols=['X1', 'X2', 'X3', 'X4', 'X5', 'X6'])\n",
        "one_hot_encoding(data, 'X2', top_10)\n",
        "data.head()"
      ],
      "metadata": {
        "id": "f0yikTELfakl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# find the top 10 most for X1 category\n",
        "top_10 = [x for x in data.X1.value_counts().sort_values(ascending=False).head(10).index]\n",
        "one_hot_encoding(data, 'X1', top_10)\n",
        "data.head()"
      ],
      "metadata": {
        "id": "S0qJ2k8OlyCt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### One Hot enocding of top variables\n",
        "#### Advantages\n",
        "- Straightforward to implement\n",
        "- Does not require hrs of variable exploration\n",
        "- Does not expand massively feature space (number of columns in the dataset)\n",
        "\n",
        "#### Disadvantages\n",
        "- Does not add any information that make the variable more predictive\n",
        "- Does not keep the information of the ignored labels\n"
      ],
      "metadata": {
        "id": "PY3FSGI4mpY5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Count / Frequency Encoding"
      ],
      "metadata": {
        "id": "u88ZWylF2C5x"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "If we have categorical variables containing many mutliple labels or high cardinality, then by using one hot encoding. we will expand the feature space drastically\n",
        "- - -\n",
        "One approach that is heavily used in kaggle competetions, is to replace each label of the categorical variable by the count, this is the amount of times each label appears in the dataset. Or the Frequency\n"
      ],
      "metadata": {
        "id": "NfLXRDvl2osx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# It is uses when the data has high cardinality i.e higher number of labels in the feature\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "data = pd.read_csv('/content/mercedesbenz.csv', usecols=['X1', 'X2'])\n",
        "data.head()\n"
      ],
      "metadata": {
        "id": "x_glcVK12Lyk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data.shape"
      ],
      "metadata": {
        "id": "O_A5smGE3rFS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## One hot encoding"
      ],
      "metadata": {
        "id": "kI1pmX9832BC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pd.get_dummies(data).shape"
      ],
      "metadata": {
        "id": "9Xs5WDMj34pc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# let's know how many unique values does the feature contains\n",
        "len(data['X1'].unique())"
      ],
      "metadata": {
        "id": "Brl9m9UR3-Yx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(data['X2'].unique())"
      ],
      "metadata": {
        "id": "z0-5erj74JTi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# let's look at how many labels\n",
        "for col in data.columns:\n",
        "  print(col, ': ', len(data[col].unique()), 'labels')\n"
      ],
      "metadata": {
        "id": "VQTAbB7e4TuO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# let's get the count of each label in variable X2\n",
        "# first we make a dictionary that maps each label to the counts\n",
        "data.X2.value_counts().to_dict()"
      ],
      "metadata": {
        "id": "fD-6wrLR4ei4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# now let's replace each label in X2 by it's count\n",
        "# first we make a dictionary that maps each label to the counts\n",
        "df_frequency_map = data.X2.value_counts().to_dict()\n"
      ],
      "metadata": {
        "id": "KHlhDIcN4wQH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data.X2 = data.X2.map(df_frequency_map)\n",
        "data.head()"
      ],
      "metadata": {
        "id": "u_zhCiCw47xN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Handling missing categorical values\n"
      ],
      "metadata": {
        "id": "OeaDwLduzfGQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data = pd.DataFrame({'Shape':['square', 'square', 'oval', 'circle', np.nan]})\n",
        "data"
      ],
      "metadata": {
        "id": "7REBzYmOmdsE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# let's use simpleImputer with most frequent strategy\n",
        "from sklearn.impute import SimpleImputer\n",
        "imputer = SimpleImputer(strategy='most_frequent')\n",
        "imputer.fit_transform(data)"
      ],
      "metadata": {
        "id": "KyrmhWIbzqyv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# let's use simpleImputer with constant strategy\n",
        "imputer = SimpleImputer(strategy='constant', fill_value='missing')\n",
        "imputer.fit_transform(data)"
      ],
      "metadata": {
        "id": "E66Y9GiO0DKu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "n4yWKxRM0Q08"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}